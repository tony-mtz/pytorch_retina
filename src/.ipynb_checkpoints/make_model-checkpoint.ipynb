{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from skimage import feature\n",
    "\n",
    "from skimage.filters import sobel\n",
    "from skimage.morphology import watershed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms as tf\n",
    "\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "# from sklearn import preprocessing\n",
    "from skimage import transform\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from imgaug import augmenters as iaaot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../networks/')\n",
    "from Att_Net import *\n",
    "# from help_functions import *\n",
    "\n",
    "# #function to obtain data for training/testing (validation)\n",
    "# from extract_patches import get_data_training\n",
    "# sys.path.insert(0, '../lib/networks/')\n",
    "\n",
    "from preprocessing import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train images/masks shape:\n",
      "(20, 1, 565, 565)\n",
      "train images range (min-max): 0.0 - 1.0\n",
      "train masks are within 0-1\n",
      "\n",
      "patches per full image: 9500\n",
      "\n",
      "train PATCHES images/masks shape:\n",
      "(190000, 1, 48, 48)\n",
      "train PATCHES images range (min-max): 0.00784313725490196 - 1.0\n",
      "(190000, 1, 48, 48)\n",
      "48 48 1\n",
      "......DONE......\n",
      "masks shape:  (190000, 2304)\n"
     ]
    }
   ],
   "source": [
    "train_img, label_img = preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190000, 1, 48, 48), (190000, 2304))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape, label_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_subimgs = 190000\n",
    "indices = list(range(N_subimgs))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "val_size = 1/10\n",
    "split = np.int_(np.floor(val_size * N_subimgs))\n",
    "\n",
    "train_idxs = indices[split:]\n",
    "val_idxs = indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eye_dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,preprocessed_images, train=True, label=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        self.images = preprocessed_images\n",
    "        if self.train:\n",
    "            self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        img = np.zeros_like(image, dtype=np.float32)\n",
    "        \n",
    "        img += image\n",
    "        label = None\n",
    "        if self.train:\n",
    "            label = self.label[idx]\n",
    "#             msk = np.zeros((2,48,48), dtype=np.long)\n",
    "#             msk[1] = label\n",
    "#             msk[0] = 1-label\n",
    "            \n",
    "#             msk += label\n",
    "            return (img, label)\n",
    "        return img\n",
    "\n",
    "eye_dataset_train = eye_dataset(train_img[train_idxs], \n",
    "                                      train=True, \n",
    "                                      label=label_img[train_idxs])\n",
    "\n",
    "eye_dataset_val = eye_dataset(train_img[val_idxs], \n",
    "                                      train=True, \n",
    "                                      label=label_img[val_idxs])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=eye_dataset_train, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=eye_dataset_val, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model_B_E(32)\n",
    "model.cuda()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, eps=.1,\n",
    "                             weight_decay=.000001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, \n",
    "                                                 milestones=[400,800,900], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_B_E(\n",
       "  (input_conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (block_1): Block_B(\n",
       "    (top_bn_relu): Sequential(\n",
       "      (0): BatchNorm2d(32, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (projection): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (residual): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (block_2): Block_B(\n",
       "    (top_bn_relu): Sequential(\n",
       "      (0): BatchNorm2d(32, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (projection): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (residual): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (block_3): Block_B(\n",
       "    (top_bn_relu): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (projection): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (residual): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (bottom): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (block4): Block_E(\n",
       "    (deconv1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (bn_relu): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (res_): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (block5): Block_E(\n",
       "    (deconv1): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (bn_relu): Sequential(\n",
       "      (0): BatchNorm2d(32, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (res_): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): BatchNorm2d(32, eps=1e-05, momentum=0.997, affine=True, track_running_stats=True)\n",
       "      (1): ReLU6(inplace)\n",
       "    )\n",
       "    (1): Dropout2d(p=0.5)\n",
       "    (2): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.0001\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, eps=.1,\n",
    "#                              weight_decay=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    total = 0.0\n",
    "    predicted = torch.exp(out)\n",
    "    size = predicted.shape[0]*predicted.shape[2]\n",
    "    pred = torch.argmax(predicted.data, dim=1)\n",
    "    total += torch.sum(pred == labels.data)\n",
    "    return total.cpu().detach().numpy()/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  1\n",
      "Training loss:....... 0.14638955519161004\n",
      "Validation loss:..... 0.14108701602176385\n",
      "\n",
      "Training accuracy:... 0.9443952145090168\n",
      "Validation accuracy.. 0.9467178841365038\n",
      "NEW BEST Loss: 0.14108701602176385 ........old best:99999\n",
      "\n",
      "NEW BEST Acc: 0.9467178841365038 ........old best:-99999\n",
      "\n",
      "EPOCH:  2\n",
      "Training loss:....... 0.1421854370496721\n",
      "Validation loss:..... 0.14191569558498435\n",
      "\n",
      "Training accuracy:... 0.9457976931617372\n",
      "Validation accuracy.. 0.9473983294105908\n",
      "NEW BEST Acc: 0.9473983294105908 ........old best:0.9467178841365038\n",
      "\n",
      "EPOCH:  3\n",
      "Training loss:....... 0.1391940840971684\n",
      "Validation loss:..... 0.135240831559756\n",
      "\n",
      "Training accuracy:... 0.946752754706709\n",
      "Validation accuracy.. 0.9482132177376861\n",
      "NEW BEST Loss: 0.135240831559756 ........old best:0.14108701602176385\n",
      "\n",
      "NEW BEST Acc: 0.9482132177376861 ........old best:0.9473983294105908\n",
      "\n",
      "EPOCH:  4\n"
     ]
    }
   ],
   "source": [
    "path = 'expr/b_e/expr1/'\n",
    "\n",
    "mean_train_losses = []\n",
    "mean_val_losses = []\n",
    "\n",
    "mean_train_acc = []\n",
    "mean_val_acc = []\n",
    "minLoss = 99999\n",
    "maxValacc = -99999\n",
    "for epoch in range(1000):\n",
    "    scheduler.step()\n",
    "    print('EPOCH: ',epoch+1)\n",
    "#     train_losses = []\n",
    "#     val_losses = []    \n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    count = 0\n",
    "    for images, labels in train_loader:    \n",
    "#         labels = labels.squeeze()\n",
    "        images = Variable(images.cuda())\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        train_acc.append(accuracy(outputs, labels))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        count +=1\n",
    "    \n",
    "    print('Training loss:.......', running_loss/count)\n",
    "#     print('Training accuracy:...', np.mean(train_acc))\n",
    "    mean_train_losses.append(running_loss/count)\n",
    "        \n",
    "    model.eval()\n",
    "    count = 0\n",
    "    val_running_loss = 0.0\n",
    "    for images, labels in val_loader:\n",
    "#         labels = labels.squeeze()\n",
    "        images = Variable(images.cuda())\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        labels = Variable(labels.cuda())\n",
    "                \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_acc.append(accuracy(outputs, labels))\n",
    "        val_running_loss += loss.item()\n",
    "        count +=1\n",
    "\n",
    "    mean_val_loss = val_running_loss/count\n",
    "    print('Validation loss:.....', mean_val_loss)\n",
    "    print('')    \n",
    "    print('Training accuracy:...', np.mean(train_acc))\n",
    "    print('Validation accuracy..', np.mean(val_acc))\n",
    "    \n",
    "    mean_val_losses.append(mean_val_loss)\n",
    "    \n",
    "    mean_train_acc.append(np.mean(train_acc))\n",
    "    \n",
    "    val_acc_ = np.mean(val_acc)\n",
    "    mean_val_acc.append(val_acc_)\n",
    "    \n",
    "   \n",
    "    if mean_val_loss < minLoss:\n",
    "        torch.save(model.state_dict(), path+'best_val_loss.pth' )\n",
    "        print(f'NEW BEST Loss: {mean_val_loss} ........old best:{minLoss}')\n",
    "        minLoss = mean_val_loss\n",
    "        print('')\n",
    "    \n",
    "    if (epoch+1)%100 ==0:\n",
    "        torch.save(model.state_dict(), path+'epoch_'+str(epoch+1)+'.pth')\n",
    "        \n",
    "        \n",
    "    if val_acc_ > maxValacc:\n",
    "        torch.save(model.state_dict(), path+'best_acc.pth' )\n",
    "        print(f'NEW BEST Acc: {val_acc_} ........old best:{maxValacc}')\n",
    "        maxValacc = val_acc_\n",
    "    \n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
